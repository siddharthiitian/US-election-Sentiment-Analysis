{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in ./lib/python3.12/site-packages (2.2.1)\n",
      "Requirement already satisfied: regex in ./lib/python3.12/site-packages (2024.11.6)\n",
      "Requirement already satisfied: textblob in ./lib/python3.12/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: transformers in ./lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: torch in ./lib/python3.12/site-packages (2.5.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: nltk>=3.8 in ./lib/python3.12/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: filelock in ./lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in ./lib/python3.12/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in ./lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in ./lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click in ./lib/python3.12/site-packages (from nltk>=3.8->textblob) (8.1.8)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.12/site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading scikit_learn-1.6.0-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy regex textblob transformers torch scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>candidate</th>\n",
       "      <th>party</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@user123</td>\n",
       "      <td>2024-11-03 08:45:00</td>\n",
       "      <td>Excited to see Kamala Harris leading the Democ...</td>\n",
       "      <td>Kamala Harris</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>120</td>\n",
       "      <td>450</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@politicsFan</td>\n",
       "      <td>2024-11-03 09:15:23</td>\n",
       "      <td>Donald Trump's policies are the best for our e...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican Party</td>\n",
       "      <td>85</td>\n",
       "      <td>300</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@greenAdvocate</td>\n",
       "      <td>2024-11-03 10:05:45</td>\n",
       "      <td>Jill Stein's environmental plans are exactly w...</td>\n",
       "      <td>Jill Stein</td>\n",
       "      <td>Green Party</td>\n",
       "      <td>60</td>\n",
       "      <td>200</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@indieVoice</td>\n",
       "      <td>2024-11-03 11:20:10</td>\n",
       "      <td>Robert Kennedy offers a fresh perspective outs...</td>\n",
       "      <td>Robert Kennedy</td>\n",
       "      <td>Independent</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@libertyLover</td>\n",
       "      <td>2024-11-03 12:35:55</td>\n",
       "      <td>Chase Oliver's libertarian stance promotes tru...</td>\n",
       "      <td>Chase Oliver</td>\n",
       "      <td>Libertarian Party</td>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id     user_handle            timestamp  \\\n",
       "0         1        @user123  2024-11-03 08:45:00   \n",
       "1         2    @politicsFan  2024-11-03 09:15:23   \n",
       "2         3  @greenAdvocate  2024-11-03 10:05:45   \n",
       "3         4     @indieVoice  2024-11-03 11:20:10   \n",
       "4         5   @libertyLover  2024-11-03 12:35:55   \n",
       "\n",
       "                                          tweet_text       candidate  \\\n",
       "0  Excited to see Kamala Harris leading the Democ...   Kamala Harris   \n",
       "1  Donald Trump's policies are the best for our e...    Donald Trump   \n",
       "2  Jill Stein's environmental plans are exactly w...      Jill Stein   \n",
       "3  Robert Kennedy offers a fresh perspective outs...  Robert Kennedy   \n",
       "4  Chase Oliver's libertarian stance promotes tru...    Chase Oliver   \n",
       "\n",
       "               party  retweets  likes sentiment  \n",
       "0   Democratic Party       120    450  positive  \n",
       "1   Republican Party        85    300  positive  \n",
       "2        Green Party        60    200  positive  \n",
       "3        Independent        40    150   neutral  \n",
       "4  Libertarian Party        30    120  positive  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove HMTL Tages, lowercase, remove @mentions\n",
    "clean = re.compile('<.*?>')\n",
    "train_csv['tweet_text'] = train_csv['tweet_text'].str.lower()\n",
    "train_csv['tweet_text'] = train_csv['tweet_text'].apply(lambda x: re.sub(clean, '',x) )\n",
    "train_csv['tweet_text'] = train_csv['tweet_text'].str.replace(r'@\\S+', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove Puncuations\n",
    "train_csv['tweet_text'] = train_csv['tweet_text'].apply(lambda x : x.translate(str.maketrans('', '',string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spelling corrections\n",
    "from textblob import TextBlob\n",
    "train_csv['tweet_text'] = train_csv['tweet_text'].apply(lambda x: TextBlob(x).correct().string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ID: tensor([[  101,  7568,  2000,  2156, 28935,  5671,  2877,  1996,  3537,  3715,\n",
      "           102]])\n",
      "Attention mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "text = train_csv['tweet_text'][0]\n",
    "\n",
    "encoding = tokenizer.batch_encode_plus( [text],# List of input texts\n",
    "    padding=True,              # Pad to the maximum sequence length\n",
    "    truncation=True,           # Truncate to the maximum sequence length if necessary\n",
    "    return_tensors='pt',      # Return PyTorch tensors\n",
    "    add_special_tokens=True    # Add special tokens CLS and SEP\n",
    ")\n",
    "\n",
    "input_ids = encoding['input_ids']  # Token IDs\n",
    "# print input IDs\n",
    "print(f'Input ID: {input_ids}')\n",
    "attention_mask = encoding['attention_mask']  # Attention mask\n",
    "# print attention mask\n",
    "print(f'Attention mask: {attention_mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Word Embeddings: torch.Size([1, 11, 768])\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings using BERT model\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    word_embeddings = outputs.last_hidden_state  # This contains the embeddings\n",
    "\n",
    "# Output the shape of word embeddings\n",
    "print(f'Shape of Word Embeddings: {word_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Text: excited to see mala harris leading the democratic charge\n",
      "tokenized Text: ['excited', 'to', 'see', 'mala', 'harris', 'leading', 'the', 'democratic', 'charge']\n",
      "Encoded Text: tensor([[  101,  7568,  2000,  2156, 28935,  5671,  2877,  1996,  3537,  3715,\n",
      "           102]])\n"
     ]
    }
   ],
   "source": [
    "# Decode the token IDs back to text\n",
    "decoded_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "#print decoded text\n",
    "print(f'Decoded Text: {decoded_text}')\n",
    "# Tokenize the text again for reference\n",
    "tokenized_text = tokenizer.tokenize(decoded_text)\n",
    "#print tokenized text\n",
    "print(f'tokenized Text: {tokenized_text}')\n",
    "# Encode the text\n",
    "encoded_text = tokenizer.encode(text, return_tensors='pt')  # Returns a tensor\n",
    "# Print encoded text\n",
    "print(f'Encoded Text: {encoded_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1750,  0.0534, -0.1162,  ..., -0.0963,  0.2406,  0.3589],\n",
       "         [ 0.6159, -0.6472, -0.3491,  ..., -0.1919,  0.4275,  0.5265],\n",
       "         [ 0.2682, -0.4770,  0.1700,  ..., -0.3569,  0.2511,  0.0313],\n",
       "         ...,\n",
       "         [-0.4254, -0.6637, -0.1005,  ..., -0.3504, -0.3146,  0.5374],\n",
       "         [-0.5015, -0.9129, -0.1265,  ...,  0.1249,  0.0892, -0.3274],\n",
       "         [ 0.6415,  0.0750, -0.3870,  ...,  0.1416, -0.6869, -0.0764]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embeddings_BERT(text):\n",
    "    text = train_csv['tweet_text'][0]\n",
    "\n",
    "    encoding = tokenizer.batch_encode_plus( [text],# List of input texts\n",
    "        padding=True,              # Pad to the maximum sequence length\n",
    "        truncation=True,           # Truncate to the maximum sequence length if necessary\n",
    "        return_tensors='pt',      # Return PyTorch tensors\n",
    "        add_special_tokens=True    # Add special tokens CLS and SEP\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids']  # Token IDs\n",
    "    # print input IDs\n",
    "    # print(f'Input ID: {input_ids}')\n",
    "    attention_mask = encoding['attention_mask']  # Attention mask\n",
    "    # print attention mask\n",
    "    # print(f'Attention mask: {attention_mask}')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        word_embeddings = outputs.last_hidden_state  # This contains the embeddings\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 768])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings_BERT(train_csv['tweet_text'][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv['tweet_text_embeded'] = train_csv['tweet_text'].apply(lambda x: word_embeddings_BERT(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv.to_csv('Data/train_embeded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "US-Election-Sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
